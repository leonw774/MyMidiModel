#!/bin/bash
# dataset parameters
MAX_SEQ_LENGTH=1024
USE_PERMUTABLE_SUBSEQ_LOSS=false
PERMUTE_MPS=false
PERMUTE_TRACK_NUMBER=false
PITCH_AUGMENTATION=0
SAMPLE_FROM_START=true

# model parameter
USE_LINEAR_ATTENTION=true
LAYERS_NUMBER=6
ATTN_HEADS_NUMBER=8
EMBEDDING_DIM=512
INPUT_NO_TEMPO=false
INPUT_NO_TIME_SIGNATURE=false

# training parameter
SPLIT_RATIO="99 1"
BATCH_SIZE=16
STEPS=1600000
VALIDATION_INTERVAL=10000
VALIDATION_STEPS=10000
LOG_HEAD_LOSSES=false
GRAD_NORM_CLIP=1.0
LEARNING_RATE=0.00008
LEARNING_RATE_WARMUP_STEPS=20000
LEARNING_RATE_DECAY_END_STEPS=1600000
LEARNING_RATE_DECAY_END_RATIO=0.0
EARLY_STOP=10

# others
USE_DEVICE='cuda'
# use accelerate by Huggingface, it will use all GPU visible, so the `export CUDA_VISIBLE_DEVICES` is needed if you don't want to use all the devices
USE_PARALLEL=true
export CUDA_VISIBLE_DEVICES=0,1,2,3
